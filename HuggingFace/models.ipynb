{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acde6c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: torch in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (2.6.0)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.46.0-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (4.50.3)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (0.2.0)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from torch) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\spurusho\\downloads\\genai\\personal\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading bitsandbytes-0.46.0-py3-none-win_amd64.whl (66.5 MB)\n",
      "   ---------------------------------------- 0.0/66.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.6/66.5 MB 7.0 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 2.1/66.5 MB 7.3 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 3.7/66.5 MB 5.5 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 4.2/66.5 MB 5.6 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 5.2/66.5 MB 4.8 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 5.8/66.5 MB 5.0 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 6.0/66.5 MB 4.3 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 7.3/66.5 MB 4.2 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 8.9/66.5 MB 4.5 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 9.4/66.5 MB 4.4 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 10.7/66.5 MB 4.6 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 12.3/66.5 MB 4.9 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 12.6/66.5 MB 4.6 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 13.9/66.5 MB 4.8 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 14.9/66.5 MB 4.7 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 16.3/66.5 MB 4.7 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 16.8/66.5 MB 4.8 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 18.1/66.5 MB 4.7 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 19.4/66.5 MB 4.8 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 20.2/66.5 MB 4.8 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 21.8/66.5 MB 4.9 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 23.3/66.5 MB 4.9 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 24.4/66.5 MB 5.0 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 24.9/66.5 MB 5.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 26.5/66.5 MB 4.9 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 26.5/66.5 MB 4.9 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 28.3/66.5 MB 4.9 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 29.6/66.5 MB 4.9 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 30.9/66.5 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 32.0/66.5 MB 5.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 33.3/66.5 MB 5.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 34.1/66.5 MB 5.0 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 35.9/66.5 MB 5.1 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 37.2/66.5 MB 5.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 38.3/66.5 MB 5.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 39.3/66.5 MB 5.1 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 40.6/66.5 MB 5.1 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 41.9/66.5 MB 5.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 43.0/66.5 MB 5.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 44.6/66.5 MB 5.2 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 45.6/66.5 MB 5.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 46.9/66.5 MB 5.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 48.2/66.5 MB 5.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 49.5/66.5 MB 5.3 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 50.9/66.5 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 50.9/66.5 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 52.4/66.5 MB 5.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 53.7/66.5 MB 5.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 54.5/66.5 MB 5.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 55.8/66.5 MB 5.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 56.6/66.5 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 56.9/66.5 MB 5.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 57.4/66.5 MB 5.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 59.0/66.5 MB 5.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 59.5/66.5 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 61.3/66.5 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 61.3/66.5 MB 5.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 63.2/66.5 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 64.5/66.5 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 64.5/66.5 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  66.3/66.5 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  66.3/66.5 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 66.5/66.5 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Installing collected packages: bitsandbytes, accelerate\n",
      "Successfully installed accelerate-1.7.0 bitsandbytes-0.46.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install requests torch bitsandbytes transformers sentencepiece accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7907c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "HFToken = os.getenv(\"hf_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15eaf450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af5ad815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "LLAMA = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "MISTRAL = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "QWEN2 = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
    "PHI = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "GEMMA2 = \"google/gemma-2-2b-it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e4e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"system\", \"content\":\"You are a helpful assistant\"},\n",
    "    {\"role\":\"user\", \"content\":\"Tell a light-hearted joke for a room of Data Scientists\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b85d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce2ba9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(LLAMA)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "inputs = tokenizer.apply_chat_template(messages, return_tensors='pt')#.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f4fe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n",
      "None of the available devices `available_devices = None` are supported by the bitsandbytes version you have installed: `bnb_supported_devices = {'cuda', 'mps', 'npu', 'hpu', '\"cpu\" (needs an Intel CPU and intel_extension_for_pytorch installed and compatible with the PyTorch version)', 'xpu'}`. Please check the docs to see if the backend you intend to use is available and how to install it: https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "None of the available devices `available_devices = None` are supported by the bitsandbytes version you have installed: `bnb_supported_devices = {'cuda', 'mps', 'npu', 'hpu', '\"cpu\" (needs an Intel CPU and intel_extension_for_pytorch installed and compatible with the PyTorch version)', 'xpu'}`. Please check the docs to see if the backend you intend to use is available and how to install it: https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLLAMA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spurusho\\Downloads\\GenAI\\Personal\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:573\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m    572\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    577\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    579\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spurusho\\Downloads\\GenAI\\Personal\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:272\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    270\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    274\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spurusho\\Downloads\\GenAI\\Personal\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4292\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4289\u001b[39m     hf_quantizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4292\u001b[39m     \u001b[43mhf_quantizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4293\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4298\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4299\u001b[39m     torch_dtype = hf_quantizer.update_torch_dtype(torch_dtype)\n\u001b[32m   4300\u001b[39m     device_map = hf_quantizer.update_device_map(device_map)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spurusho\\Downloads\\GenAI\\Personal\\venv\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py:84\u001b[39m, in \u001b[36mBnb4BitHfQuantizer.validate_environment\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_multi_backend_available\n\u001b[32m     83\u001b[39m bnb_multibackend_is_enabled = is_bitsandbytes_multi_backend_available()\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[43mvalidate_bnb_backend_availability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mfrom_tf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mfrom_flax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m sure the weights are in PyTorch format.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     90\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spurusho\\Downloads\\GenAI\\Personal\\venv\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:558\u001b[39m, in \u001b[36mvalidate_bnb_backend_availability\u001b[39m\u001b[34m(raise_exception)\u001b[39m\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_bitsandbytes_multi_backend_available():\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_validate_bnb_multi_backend_availability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _validate_bnb_cuda_backend_availability(raise_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spurusho\\Downloads\\GenAI\\Personal\\venv\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:515\u001b[39m, in \u001b[36m_validate_bnb_multi_backend_availability\u001b[39m\u001b[34m(raise_exception)\u001b[39m\n\u001b[32m    509\u001b[39m     err_msg = (\n\u001b[32m    510\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of the available devices `available_devices = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavailable_devices\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` are supported by the bitsandbytes version you have installed: `bnb_supported_devices = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbnb_supported_devices_with_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease check the docs to see if the backend you intend to use is available and how to install it: https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    512\u001b[39m     )\n\u001b[32m    514\u001b[39m     logger.error(err_msg)\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(err_msg)\n\u001b[32m    517\u001b[39m logger.warning(\u001b[33m\"\u001b[39m\u001b[33mNo supported devices found for bitsandbytes multi-backend.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: None of the available devices `available_devices = None` are supported by the bitsandbytes version you have installed: `bnb_supported_devices = {'cuda', 'mps', 'npu', 'hpu', '\"cpu\" (needs an Intel CPU and intel_extension_for_pytorch installed and compatible with the PyTorch version)', 'xpu'}`. Please check the docs to see if the backend you intend to use is available and how to install it: https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(LLAMA, device_map = \"auto\", quantization_config = quant_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388748d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
