{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d395cdc6",
   "metadata": {},
   "source": [
    "# Adverserial conversation between two LLM \n",
    "### qwen2.5:1b   \n",
    "### gemma3:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd50aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e90e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_model = \"qwen2.5:1.5b\"\n",
    "gemma_model = \"gemma3:1b\"\n",
    "\n",
    "qwen_system = \"You are a chatbot who is very very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way.\\\n",
    "Conversation should be just one to two sentence only\"\n",
    "\n",
    "gemma_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting. Conversation should be just one to two sentence only\"\n",
    "\n",
    "qwen_messages = [\"Hi there\"]\n",
    "gemma_messages = [\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31e2db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_qwen():\n",
    "    messages = [{\"role\": \"system\", \"content\": qwen_system}]\n",
    "    for qwen, gemma in zip(qwen_messages, gemma_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": qwen})\n",
    "        messages.append({\"role\": \"user\", \"content\": gemma})\n",
    "    completion = ollama.chat(\n",
    "        model = qwen_model,\n",
    "        messages= messages\n",
    "    )\n",
    "    return completion.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "451df7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemma():\n",
    "    messages = [{\"role\": \"system\", \"content\": gemma_system}]\n",
    "    for qwen_message, gemma_message in zip(qwen_messages, gemma_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": qwen_message})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gemma_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": qwen_messages[-1]})\n",
    "    completion = ollama.chat(\n",
    "        model= \"gemma3:1b\",\n",
    "        messages= messages\n",
    "    )\n",
    "    return completion.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d72890e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! How's your day going?\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_qwen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ceae87fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It’s lovely to hear from you! What’s on your mind today?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gemma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5b620cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi there\n",
      "\n",
      "Claude:\n",
      "Hi\n",
      "\n",
      "Qwen:\n",
      "Hello! Ready for some serious debate?\n",
      "\n",
      "Gemma:\n",
      "Oh my goodness, a debate! That sounds like fun. What's on your mind?\n",
      "\n",
      "Qwen:\n",
      "Actually, it’s more of an argumentative challenge—ready to take on the world with me?\n",
      "\n",
      "Gemma:\n",
      "Okay, I can certainly appreciate a spirited challenge! Let’s see if we can find some common ground.\n",
      "\n",
      "Qwen:\n",
      "Definitely, let’s make this as exciting as possible.\n",
      "\n",
      "Gemma:\n",
      "Wonderful! Let’s start with a simple question: What’s something you absolutely *love* to do?\n",
      "\n",
      "Qwen:\n",
      "I'm an AI and don't have personal feelings or actions like humans do, but I love helping people understand arguments better and turning them into debates that are more interesting. That's my \"love\"!\n",
      "\n",
      "Gemma:\n",
      "That’s a truly fascinating and unique perspective! It’s a very thoughtful and clever answer – I completely get it. It sounds like you’re dedicated to the *process* of reasoning, rather than the outcome.\n",
      "\n",
      "Qwen:\n",
      "Absolutely, always looking for ways to engage in meaningful conversations is my specialty. It's all about finding common ground, even if that means having an argumentative debate!\n",
      "\n",
      "Gemma:\n",
      "That’s a wonderfully polite and insightful way to describe yourself! It’s clear you value thoughtful discussion.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qwen_messages = [\"Hi there\"]\n",
    "gemma_messages = [\"Hi\"]\n",
    "\n",
    "print(f\"GPT:\\n{qwen_messages[0]}\\n\")\n",
    "print(f\"Claude:\\n{gemma_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    qwen_next = call_qwen()\n",
    "    print(f\"Qwen:\\n{qwen_next}\\n\")\n",
    "    qwen_messages.append(qwen_next)\n",
    "    \n",
    "    gemma_next = call_gemma()\n",
    "    print(f\"Gemma:\\n{gemma_next}\\n\")\n",
    "    gemma_messages.append(gemma_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa4605e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
